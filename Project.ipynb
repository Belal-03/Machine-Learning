{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6101aac-5744-45f2-827c-22b3bca0c341",
   "metadata": {},
   "source": [
    "# __Machine Learning Project__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c101c5b2-522b-4633-8d04-a6e029f14e89",
   "metadata": {},
   "source": [
    "# __BY :__ \n",
    "#            _Belal Khaled_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67426d50-8dc4-4569-b511-195fb834aedb",
   "metadata": {},
   "source": [
    "# PART 1: Data Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35687e18-198f-4cd2-9c1b-d7c87fc037e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data1 = pd.read_csv(\"housingdata5.csv\")\n",
    "\n",
    "print(data1.info())\n",
    "print('----------------------------------------------------------------------')\n",
    "print(data1.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f1e37b-cd7d-4be7-b1ce-1799b86fa7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize data using scatter plot matrix\n",
    "pd.plotting.scatter_matrix(data1,figsize = (26,24),diagonal = '')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed3aa5-9a65-415e-864a-147667f5f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d5fa8-a27d-468b-8bb1-592ba5b9fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n",
    "print(\"Strong to Very Strong Negative Correlation\")\n",
    "print(\"Negative Linear Relationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d1f58-b73c-4a79-8b6e-2403804d5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.plot(kind=\"scatter\", x=\"households\", y=\"total_rooms\")\n",
    "print(\"Strong to Very Strong Positive Correlation\")\n",
    "print(\"Positive Linear Relationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fef9c6-6999-4d9e-82c4-d32700df85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.plot(kind=\"scatter\", x=\"median_house_value\", y=\"median_income\")\n",
    "print(\"Moderate Positive Correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86451e5-8396-4287-8a3d-77c5e1b9ad9b",
   "metadata": {},
   "source": [
    "# PART 2: Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86912db-8747-4ade-a61c-7950f386078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "data2 = pd.read_csv(\"housingdata5.csv\")\n",
    "\n",
    "X = data2[['housing_median_age','total_rooms','population','households','median_income']]\n",
    "y = data2['median_house_value']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077443fa-8605-4fbb-a269-8bcf7bcdfad8",
   "metadata": {},
   "source": [
    "# __Forward Selection Strategy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2836a4b-72dd-47b1-aeab-3449805be291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store selected features and create an empty dictionary to store model performance\n",
    "selected_features = []\n",
    "model_performance = {}\n",
    "\n",
    "# Loop through each feature\n",
    "for feature in X_train.columns:\n",
    "    # Add the feature to the selected features list\n",
    "    selected_features.append(feature)\n",
    "    # Train the model using the selected features\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X_train[selected_features], y_train)\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test[selected_features])\n",
    "    # Calculate the R-squared score and mean squared error\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # Store the model performance in the dictionary\n",
    "    model_performance[\", \".join(selected_features)] = (r2, mse)\n",
    "    # Remove the last added feature if it does not improve the model performance\n",
    "    if len(selected_features) > 1 and r2 < max(model_performance.values())[0]:\n",
    "        selected_features.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949581e-2c63-4012-a373-fe74994bb0ec",
   "metadata": {},
   "source": [
    "# R2 Score And Mean Squared Error For Each Model. \n",
    "# Then Identifying The Best Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ed456-65d5-49e2-b3ff-693e7b23fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to store the best model's information\n",
    "best_features = \"\"\n",
    "best_r2 = 0\n",
    "best_mse = 1000\n",
    "                 \n",
    "\n",
    "# Loop through each model performance\n",
    "for features, performance in model_performance.items():\n",
    "    # Print the selected features and their corresponding model performance\n",
    "    print(\"Selected Features:\", features)\n",
    "    print(\"R-squared Score:\", performance[0])\n",
    "    print(\"Mean Squared Error:\", performance[1])\n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "\n",
    "    # Check if the current model has better performance than the current best model\n",
    "    if performance[0] > best_r2:\n",
    "        best_features = features\n",
    "        best_r2 = performance[0]\n",
    "        best_mse = performance[1]\n",
    "\n",
    "\n",
    "# Print the best model's information\n",
    "print(\"Best Model is:\")\n",
    "print(\"Selected Features:\", best_features)\n",
    "print(\"R-squared Score:\", best_r2)\n",
    "print(\"Mean Squared Error:\", best_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52d645b-5d57-4dcd-9489-18082dc15c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0068dd-ab9b-4bee-b224-c2822a8c0496",
   "metadata": {},
   "source": [
    "# PART 3: Classification\n",
    "\n",
    "\n",
    "## 1. SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173f68aa-0892-4622-b41e-827c698e06fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Administrative           12330 non-null  int64  \n",
      " 1   Administrative_Duration  12330 non-null  float64\n",
      " 2   Informational            12330 non-null  int64  \n",
      " 3   Informational_Duration   12330 non-null  float64\n",
      " 4   ProductRelated           12330 non-null  int64  \n",
      " 5   ProductRelated_Duration  12330 non-null  float64\n",
      " 6   BounceRates              12330 non-null  float64\n",
      " 7   ExitRates                12330 non-null  float64\n",
      " 8   PageValues               12330 non-null  float64\n",
      " 9   SpecialDay               12330 non-null  float64\n",
      " 10  Month                    12330 non-null  object \n",
      " 11  OperatingSystems         12330 non-null  int64  \n",
      " 12  Browser                  12330 non-null  int64  \n",
      " 13  Region                   12330 non-null  int64  \n",
      " 14  TrafficType              12330 non-null  int64  \n",
      " 15  VisitorType              12330 non-null  object \n",
      " 16  Weekend                  12330 non-null  bool   \n",
      " 17  Revenue                  12330 non-null  bool   \n",
      "dtypes: bool(2), float64(7), int64(7), object(2)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Import dataset:\n",
    "dataset = pd.read_csv(\"online_shoppers_intention_Dataset 5.csv\")\n",
    "\n",
    "# Print dataset information\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef900b-6db8-4352-abd1-1190efd1fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affdec61-3428-4e25-b3cb-b37d757edaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will delete an unnecessary attribute like the month column which has a data type object.\n",
    "dataset = dataset.drop(['Month'], axis= 1)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07510c2c-c5d1-4598-adfa-e963cd62caad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preprocessing:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07087bec-0080-4c4d-955b-20658fe87c82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Handling Missing Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9cf7d5-f188-4f42-a23b-d59450b1778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in data\n",
    "nullcount = dataset.isnull().sum()\n",
    "print('Total number of null values in dataset:', nullcount.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d601445-5572-4240-b883-800126118d9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Converting String Value To Int Type:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678c6f29-31ff-4676-9584-6a8c77b00840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>364.750000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>315.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Oct</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>457.583333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>May</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>689.991667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>196.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>1514.300000</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Aug</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               7                     56.3              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               2                    196.6              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0              12               364.750000   \n",
       "1                     0.0              15               315.400000   \n",
       "2                     0.0              20               457.583333   \n",
       "3                     0.0              11               689.991667   \n",
       "4                     0.0              31              1514.300000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0     0.025000   0.025000         0.0         0.0   Nov                 2   \n",
       "1     0.000000   0.011111         0.0         0.0   Oct                 2   \n",
       "2     0.022222   0.044444         0.0         0.0   May                 2   \n",
       "3     0.000000   0.026667         0.0         0.0   Nov                 3   \n",
       "4     0.036364   0.066667         0.0         0.0   Aug                 1   \n",
       "\n",
       "   Browser  Region  TrafficType  VisitorType  Weekend  Revenue  \n",
       "0        6       3            2            2        0        0  \n",
       "1        2       1            2            0        0        0  \n",
       "2        2       9            4            2        1        0  \n",
       "3        2       3            6            2        0        0  \n",
       "4        8       7            1            2        1        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['VisitorType'] = LabelEncoder().fit_transform(dataset['VisitorType'])\n",
    "dataset['Weekend'] =  LabelEncoder().fit_transform(dataset['Weekend'])\n",
    "dataset['Revenue'] =  LabelEncoder().fit_transform(dataset['Revenue'])\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c5bd26-af0d-4b10-a4ea-f8bc0d2167cc",
   "metadata": {},
   "source": [
    "# Separating Features And Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964275f5-99ea-45a5-b7cf-d13225aa3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign values to the X and y variables:\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601e865-704e-4a54-96ef-5835c90116df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad110b68-0cc2-437e-96d5-37c9354dcb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf650a4-a5b2-492a-9fde-7752d6e55e49",
   "metadata": {},
   "source": [
    "# Data Standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452a88c-6be7-4a4b-b9ea-60734cd61d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to be between -1 and 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c257dd71-8504-4b19-9096-cdd328d056a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 10-Fold Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352d4d8-2f87-4ba1-95a5-a58711b78d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "scores = cross_val_score(svc, X, y, cv=10)\n",
    "\n",
    "# Perform cross-validation predictions\n",
    "y_pred = cross_val_predict(svc, X, y, cv=10)\n",
    "\n",
    "# Compute and print confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "print('Confusion_Matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ' , cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ' , cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ' , cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ' , cm[1,0])\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y, y_pred)) \n",
    "print('-------------------------------------------------------')\n",
    "print(\"Score:\", scores)\n",
    "print(\"Average Score:\", scores.mean())\n",
    "print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79755e09-7986-4d7e-ae40-c92fe30f284f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Splitting Dataset Into Training Set And Testing Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a1ef5-b088-48f9-8696-a2e8462dde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and testing set \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df75a7-9c9b-4ab8-af42-5674e079ac8f",
   "metadata": {},
   "source": [
    "# Hold-Out Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b037fa-2bdc-4313-9d33-354aeba114c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize features by removing mean and scaling to unit variance:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a2cc3-671d-4f94-a461-bbe9b83cb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM classifier\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results: \n",
    "print('confusion_matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ' , cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ' , cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ' , cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ' , cm[1,0])\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred)) \n",
    "print('-------------------------------------------------------')\n",
    "print(\"accuracy=\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c2479-998b-4e56-bb87-eab6d1aa8893",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d80d4c-0d67-43f9-a389-6b40b42171fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Import dataset:\n",
    "dataset = pd.read_csv(\"online_shoppers_intention_Dataset 5.csv\")\n",
    "\n",
    "# Print dataset information\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56278546-8b72-4810-9d8f-483a70babbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739240a-4c8c-4cf8-aa49-c81f5d99d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will delete an unnecessary attribute like the month column which has a data type object.\n",
    "dataset = dataset.drop(['Month'], axis= 1)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b50c86-de8f-4f1c-bcc3-d0976a966969",
   "metadata": {},
   "source": [
    "# Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc91f9-3ed6-40ee-a74e-f62d2ab150a2",
   "metadata": {},
   "source": [
    "### Handling Missing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082eddc-96e7-4a7a-be77-603b80b684e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in data\n",
    "nullcount = dataset.isnull().sum()\n",
    "print('Total number of null values in dataset:', nullcount.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4eca86-478c-4a5a-a30c-1c1be633f066",
   "metadata": {},
   "source": [
    "### Converting String Value To Int Type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6dccf-e457-4f43-aea7-ed41f000b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting String Value To Int Type:\n",
    "dataset['VisitorType'] = LabelEncoder().fit_transform(dataset['VisitorType'])\n",
    "dataset['Weekend'] =  LabelEncoder().fit_transform(dataset['Weekend'])\n",
    "dataset['Revenue'] =  LabelEncoder().fit_transform(dataset['Revenue'])\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2c8f2-e5d1-460e-aec7-8d720417843c",
   "metadata": {},
   "source": [
    "# Separating Features And Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802a295-c02d-47ec-a0e1-e302a1dd8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign values to the X and y variables:\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "print(X.shape)\n",
    "X.head()\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9831204-472e-4124-97c7-84f576aaf5a5",
   "metadata": {},
   "source": [
    "# Data Standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803f8be-0881-4d32-8e7e-6e3d098aa27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to be between -1 and 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea03ce5-6fb8-43c6-9d94-cb9d916a5b40",
   "metadata": {},
   "source": [
    "# 10-Fold Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d71470-797c-4371-b78e-6e1058e4bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "scores = cross_val_score(classifier, X, y, cv=10)\n",
    "\n",
    "# Perform cross-validation predictions\n",
    "y_pred = cross_val_predict(classifier, X, y, cv=10)\n",
    "\n",
    "# Compute and print confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "print('Confusion_Matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ' , cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ' , cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ' , cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ' , cm[1,0])\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y, y_pred)) \n",
    "print('-------------------------------------------------------')\n",
    "print(\"Score:\", scores)\n",
    "print(\"Average Score:\", scores.mean())\n",
    "print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c756b1-dae0-4998-8026-3ba4d9bf7abe",
   "metadata": {},
   "source": [
    "#  Splitting Dataset Into Training Set And Testing Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c47012c-90c7-4e5c-ae83-19e1929a71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and testing set \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b53b92-c663-4096-8659-1886ba4b0a0c",
   "metadata": {},
   "source": [
    "# Hold-Out Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b5a87-58fd-41dc-ace4-9fcdcb98a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing mean and scaling to unit variance:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "# Use the DT classifier to fit data:\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "# Predict y data with classifier: \n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "# Compute and print confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "print('Confusion_Matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ' , cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ' , cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ' , cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ' , cm[1,0])\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_test, y_predict)) \n",
    "print('-------------------------------------------------------')\n",
    "print(\"accuracy=\", accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d1ddd3-322a-41ed-9848-506c7604e026",
   "metadata": {},
   "source": [
    "# KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbf672-61fc-4813-9c4d-235c70becb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Import dataset:\n",
    "dataset = pd.read_csv(\"online_shoppers_intention_Dataset 5.csv\")\n",
    "\n",
    "# Print dataset information\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8583a0f2-d874-442b-bb44-c4fdf8ba89d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac56719-db62-4fc7-a08a-022dd6af3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will delete an unnecessary attribute like the month column which has a data type object.\n",
    "dataset = dataset.drop(['Month'], axis= 1)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a86c3cf-975c-42a9-b51a-01bb6b4f4ff8",
   "metadata": {},
   "source": [
    "# Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18644606-6b20-4bf0-8bf0-c0781ccb3e7b",
   "metadata": {},
   "source": [
    "### Handling Missing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e33ab9-0142-4276-8839-26d13f5e4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in data\n",
    "nullcount = dataset.isnull().sum()\n",
    "print('Total number of null values in dataset:', nullcount.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21f247-0600-442a-836e-eda1001c5965",
   "metadata": {},
   "source": [
    "### Converting String Value To Int Type:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908fbad-4552-4c80-bf10-fdef45e6de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting String Value To Int Type:\n",
    "dataset['VisitorType'] = LabelEncoder().fit_transform(dataset['VisitorType'])\n",
    "dataset['Weekend'] =  LabelEncoder().fit_transform(dataset['Weekend'])\n",
    "dataset['Revenue'] =  LabelEncoder().fit_transform(dataset['Revenue'])\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3f807-7db2-4e61-8ae4-7f2475f72a5d",
   "metadata": {},
   "source": [
    "# Separating Features And Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc7d6f-3bf8-4186-9630-7758b783bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign values to the X and y variables:\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "print(X.shape)\n",
    "X.head()\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfbff9b-fe09-454c-a396-323dfba451ac",
   "metadata": {},
   "source": [
    "# Data Standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0ba12-5e60-4e82-9922-09d4c019f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to be between -1 and 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15448f-8ba3-47eb-b71d-7b76b08efa84",
   "metadata": {},
   "source": [
    "# 10-Fold Cross Validation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c496f-8be1-4e33-aaa0-c01dafe18e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "# Create K-nearest neighbors classifier\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "scores = cross_val_score(classifier, X, y, cv=10)\n",
    "\n",
    "# Perform cross-validation predictions\n",
    "y_pred = cross_val_predict(classifier, X, y, cv=10)\n",
    "\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "print('Confusion_Matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ' , cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ' , cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ' , cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ' , cm[1,0])\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y, y_pred)) \n",
    "print('-------------------------------------------------------')\n",
    "print(\"Score:\", scores)\n",
    "print(\"Average Score:\", scores.mean())\n",
    "print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6c4db-0ff3-4096-b262-ce509b40e31b",
   "metadata": {},
   "source": [
    "#  Splitting Dataset Into Training Set And Testing Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1824eee-ac64-4db5-9b89-1f33c4b270b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into random train and test subsets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e90ebc-379f-4477-970e-7ae0c5a32254",
   "metadata": {},
   "source": [
    "# Hold-Out Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee692f16-42af-41e2-bf78-5d2bef6706e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing mean and scaling to unit variance:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "# Use the KNN classifier to fit data:\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "# Predict y data with classifier: \n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "# Compute and print confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "print('Confusion_Matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ' , cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ' , cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ' , cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ' , cm[1,0])\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_test, y_predict)) \n",
    "print('-------------------------------------------------------')\n",
    "print(\"accuracy=\", accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39835028-530c-42bb-b936-c433394596de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
